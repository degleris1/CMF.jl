{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling BenchmarkTools [6e4b80f9-dd63-53aa-95a3-0cdb28fa8baf]\n",
      "└ @ Base loading.jl:1273\n"
     ]
    }
   ],
   "source": [
    "using FFTW\n",
    "using LinearAlgebra\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "function s_dot(Wl::Matrix, H::Matrix, lag)\n",
    "    K, T = size(H)\n",
    "\n",
    "    if (lag < 0)\n",
    "        return Wl * H[:, 1-lag:T]\n",
    "\n",
    "    else  # lag >= 0\n",
    "        return Wl * H[:, 1:T-lag]\n",
    "    end\n",
    "end\n",
    "\n",
    "function tensor_conv(W, H)\n",
    "    L, N, K = size(W)\n",
    "    T = size(H)[2]\n",
    "\n",
    "    pred = zeros(N, T)\n",
    "    for lag = 0:(L-1)\n",
    "        pred[:, lag+1:T] += s_dot(W[lag+1, :, :], H, lag)\n",
    "    end\n",
    "    return pred\n",
    "end\n",
    "\n",
    "N, T, L, K = 30, 50, 7, 2\n",
    "W = rand(L, N, K)\n",
    "H = rand(K, T)\n",
    "H[:, end-L:end] .= 0\n",
    "\n",
    "X = tensor_conv(W, H);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(Wpad) = (64, 30, 2)\n",
      "size(Hpad) = (2, 64)\n"
     ]
    }
   ],
   "source": [
    "# Zero pad H\n",
    "Hpad = [zeros(K, L) H zeros(K, L)]\n",
    "\n",
    "# Zero pad W\n",
    "Wpad = vcat(zeros(L+T, N, K), W)\n",
    "\n",
    "@show size(Wpad)\n",
    "@show size(Hpad);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(Hpadhat1) = (2, 64)\n",
      "size(Hpadhat2) = (2, 64)\n",
      "norm(Hpadhat1 - Hpadhat2) = 5.521894863136994e-15\n"
     ]
    }
   ],
   "source": [
    "# Take fft of H\n",
    "Hpadhat1 = Array{Complex, 2}(undef, size(Hpad)...)\n",
    "for k = 1:K\n",
    "    Hpadhat1[k, :] = fft(Hpad[k, :])\n",
    "end\n",
    "Hpadhat2 = fft(Hpad, 2)\n",
    "\n",
    "@show size(Hpadhat1)\n",
    "@show size(Hpadhat2)\n",
    "@show norm(Hpadhat1 - Hpadhat2)\n",
    "\n",
    "ftH = Hpadhat2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(ftW1) = (64, 30, 2)\n",
      "size(ftW2) = (64, 30, 2)\n",
      "norm(ftW1 - ftW2) = 1.588150543073792e-14\n"
     ]
    }
   ],
   "source": [
    "# Take fft of W\n",
    "ftW1 = Array{Complex, 3}(undef, size(Wpad)...)\n",
    "for k = 1:K\n",
    "    for n = 1:N\n",
    "        ftW1[:, n, k] = fft(Wpad[:, n, k])\n",
    "    end\n",
    "end\n",
    "ftW2 = fft(Wpad, 1)\n",
    "\n",
    "@show size(ftW1)\n",
    "@show size(ftW2)\n",
    "@show norm(ftW1 - ftW2)\n",
    "\n",
    "ftW = ftW2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm(X - ifftX) = 2.2192279392499284e-14\n",
      "norm(fft([X zeros(N, 2L)], 2) - ftX) = 2.0132894844227993e-13\n"
     ]
    }
   ],
   "source": [
    "# Compute tensor conv\n",
    "ftX = Array{Complex{Float64}, 2}(undef, N, T+2*L)\n",
    "ftX .= 0.0\n",
    "\n",
    "for n = 1:N\n",
    "    for k = 1:K\n",
    "        ftX[n, :] .+= ftW[:, n, k] .* ftH[k, :]\n",
    "    end\n",
    "end\n",
    "\n",
    "ifftX = real.(ifft(ftX, 2))[:, 1:end-2L]\n",
    "\n",
    "@show norm(X - ifftX);\n",
    "@show norm(fft([X zeros(N, 2L)], 2) - ftX)\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm(tensor_conv(W, H) - tensor_convft(W, H)) = 23.20900885154874\n",
      "  446.559 μs (246 allocations: 342.89 KiB)\n"
     ]
    }
   ],
   "source": [
    "function tensor_convft(W, H)\n",
    "    ftW = fft(vcat(zeros(L+T, N, K), W), 1)\n",
    "    ftH = copy(fft(Hpad, 2)')\n",
    "    \n",
    "    ftX = Array{Complex{Float64}, 2}(undef, N, T+2*L)\n",
    "    ftX .= 0.0\n",
    "\n",
    "    for k = 1:K\n",
    "        @views ftX .+= (ftH[:, k] .* ftW[:, :, k])'\n",
    "    end\n",
    "    \n",
    "    return real.(ifft(ftX, 2))[:, L+1:end-L]\n",
    "end\n",
    "\n",
    "@show norm(tensor_conv(W, H) - tensor_convft(W, H))\n",
    "\n",
    "#@btime tensor_conv(W, H) samples=1\n",
    "@btime tensor_convft(W, H) samples=1\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×50 Array{Float64,2}:\n",
       " 0.00831528  0.000742991  -0.00264099  …  0.00786458  0.00955813   0.0171293\n",
       " 0.00387465  0.00622225    0.0147462      0.0286908   0.000501934  0.0258675"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solve LS for H\n",
    "# Set H = inv(S'S + 2I) * B\n",
    "#  in the fourier domain\n",
    "B = rand(K, T) .+ 3\n",
    "\n",
    "ftW = fft(vcat(zeros(L+T, N, K), W), 1)\n",
    "ftB = fft([zeros(K,L) B zeros(K,L)], 2)\n",
    "\n",
    "# Solve for each column of H via KxK LS\n",
    "ftH = Array{Complex{Float64}, 2}(undef, K, T+2*L)\n",
    "\n",
    "for t = 1:T\n",
    "    ftH[:, t] = (ftW[t, :, :]'ftW[t, :, :] .+ 2) \\ ftB[:, t]\n",
    "end\n",
    "\n",
    "iftH = real.(ifft(ftH)[:, 1:end-2L])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
